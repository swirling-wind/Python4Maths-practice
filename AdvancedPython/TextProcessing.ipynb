{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing in Python\n",
    "Python has a large number of libraries and built-in functions for dealing with text. This notebook provides an introduction to some of these. It includes a section or *regular expressions* (which are not unique to Python) and then goes through an exercise of web scraping and automatically generating a report out of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "You want to put together a report with some tables and perhaps a figure or two based on data obtained from some web sites. Both reading the contents of the web pages and writing the report requires dealing with text. This is something that Python is excellent at. There is a large number of libraries that can assist depending on the specific task. Here we are not going to cover all of these but just provide enough of an introduction to what is available to get you started. \n",
    "\n",
    "The other common use of the same types of Python functions is when trying to make sense of a set of computational experiments. It's not uncommon to have run a program on a large number of data sets. Each time your program runs it might produce a number of outputs, perhaps including just some log files originally designed more with debugging than with reporting in mind. You know need to create a table of results or some figures from these to include in your journal paper. Again Python can be used to both process all of the text input files and to produce a nicely formatted output (for example via LaTeX or HTML)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "\n",
    "When dealing with text files, regular expressions are your friend. They form a mini-language of their own for expressing string patterns. Regular expressions are not unique to python, with relatively similar syntax used in a variety of tools (particularly in linux/unix). The [regular expression documentation](https://docs.python.org/3/library/re.html) gives all the details, but to get you started the string `r\"^[abc]\\d*\"` would match any line that \n",
    "   * is at the start of a line (as incdicated by the `^`)\n",
    "   * has one of the characters in the set {'a','b','c'} (written as \"[abc]\") first\n",
    "   * is followed by zero or more digits \"\\d\" = digit, * means \"zero or more\", you could use \"+\" for \"one or more\"\n",
    "   * the string is written as a raw string (`r\"\"`) to make sure that \"\\\" is not interpreted as an escape character - since regular expressions make frequent use of the backslash\n",
    "   * it is also particularly useful and easy to mark a substring as a _group_. For example `r\"([xyz]+)\\1\"` means that we have a group consisting of one or more characters in {x,y,z} followed by the same group (group 1) repeating a second time. \n",
    "   * `import re` to get the library, then use `re.search(pattern,string)` to find a pattern in the given string, `re.search(pattern,string).group(1)` would give the substring of the first group in the time the pattern was matched (if the pattern was found at all).\n",
    "\n",
    "#### Regular expression testing\n",
    "To test your skills at writing regular expressions, try the following exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: Some;Australia;Capital;Figure\n",
      "3: enumerate;nested;array\n",
      "7: 15.3;-100;1.2e-03;NaN;1;4;+2E+6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.3, -100.0, 0.0012, nan, 1.0, 4.0, 2000000.0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def testre(regex,string):\n",
    "    \"Simple test function to print all matches of a regular expression in a string\"\n",
    "    matches = re.findall(regex,string)\n",
    "    print(\"%d:\"%len(matches),\";\".join(matches))\n",
    "    return matches\n",
    "          \n",
    "testre(r\"INSERT_HERE\", # insert regular expressions to find any capitalised words with 2 letters or more\n",
    "    \"\"\"Some words, like Australia I know, have Capital letters, see Figure 3 for more\"\"\"\n",
    "    )# should find 4: Some;Australia;Capital;Figure\n",
    "testre(r\"INSERT_HERE\", # outer LaTeX environments: \\begin{somename}up to\\end{somename}\n",
    "      r\"\"\"\\begin{enumerate}\\item\n",
    "      \\end{enumerate}\\begin{nested}\\begin{env}\\end{env}\\end{nested}\n",
    "      \\begin{test}\\end{fail}  \\begin{array}1 & 2\\\\3 & 4 \\\\end{array}\n",
    "      \"\"\") # should find 3: enumerate;nested;array  the test/fail pair is incorrect and not to be matched\n",
    "[float(f) for f in \n",
    " testre(r\"INSERT_HERE\", \n",
    "        # find floating point numbers (including integers and scientific notation)\n",
    "      \"15.3 - -100 1.2e-03  NaN 1ee4 +2E+6 \")  # 7: 15.3;-100;1.2e-03;NaN;1;4;+2E+6\n",
    "] # output 15.3, -100.0, 0.0012, nan, 1.0, 4.0, 2000000.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Report on Research Collaboration in a Department\n",
    "\n",
    "The aim of this exercise is to write a small report on the level of research collaboration, as indicated by co-authorship of papers, that is happening within a department at Monash. This might be the School of Mathematics, but feel free to pick any school.\n",
    "\n",
    "## Find all Staff\n",
    "First we want to find a list of all people in the school. This can be done fairly easily by looking at `https://reasearch.monash.edu.en/organisations/school-of-mathematics/persons/` (insert the name of whatever department you want instead of `school-of-mathematics` here.\n",
    "Note that there may be multiple pages of people. You can get each of these by changing the URL to end with `.../persons/?page=i` where $i=0,1,2,...$ depending on how many pages the school has (until you don't get any more people).\n",
    "\n",
    "To read a web page there are (as always) multiple ways to do this:\n",
    "* The standard python standard library `urllib.request` contains the function `urlopen()`. You can use `urlopen(\"http...\").read()` to get the contents of the web page as binary string (use `.decode(\"utf8\")` to convert this into a standard Python unicode string)\n",
    "* The `requests` library is included in may distributions and has some more additional functionality. For our purposes the main difference is one of syntax. `requests.get(\"http...\").text` will get the contents of the page as a python string.\n",
    "\n",
    "Use what you know about regular expressions to create a function that finds all of the URL's of people in a department. Note that each peron will have a description that looks something like this in HTML:\n",
    "\n",
    "```HTML\n",
    "<div class=\"rendering rendering_person rendering_short rendering_person_short\"><h2 class=\"title\"><a rel=\"Person\" href=\"https://research.monash.edu/en/persons/andreas-ernst\" class=\"link person\"><span>Andreas Ernst</span></a></h2><ul class=\"relations email\"><li class=\"email\"><a href=\"mailto:Andreas.Ernst@monash.edu\" class=\"link\"><span>Andreas.Ernst@monash.edu</span></a></li></ul><ul class=\"relations organisations\"><li><a rel=\"Organisation\" href=\"https://research.monash.edu/en/organisations/school-of-mathematics\" class=\"link organisation\"><span>School of Mathematics</span></a><span class=\"minor dimmed\"> - Professor</span></li></ul><p class=\"type\"><span class=\"family\">Person: </span>Academic</p></div>\n",
    "```\n",
    "\n",
    "You only want the part that follows the first `href` in this for each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 staff: [] ...\n"
     ]
    }
   ],
   "source": [
    "BASENAME=\"https://research.monash.edu/en/organisations/\"\n",
    "import re,requests\n",
    "\n",
    "def findAllStaff(orgName=\"school-of-mathematics\"):\n",
    "    \"\"\"Given the name of a school/department return a list of staff URLs (as strings).\n",
    "    Assumes that BASENAME+orgName is a valid URL.\"\"\"\n",
    "    ## add your code here\n",
    "    return []\n",
    "staffurls = findAllStaff(\"school-of-mathematics\")\n",
    "print(\"Found %d staff:\"%len(staffurls),staffurls[:2],\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse staff web pages\n",
    "We want to get all of the content of the staff pages - or at least the information about their name and list of publications with authors.\n",
    "\n",
    "We could again do this by using regular expressions, but there are more sophisticated options. Here we are going to use the `html.parser` library. The interface of this library requires creating a subclass.  *Note:* this is quite a common pattern for object oriented programming languages. As a simple example of this, imagine that you are writing an optimisation algorithm that needs both the value of the function to be optimised and the derivative. You might now define something like\n",
    "```Python\n",
    "class AbstractFunction:\n",
    "    def value(self,x):\n",
    "        return 0\n",
    "    def derivative(self,x): # a crude approximation to the derivative\n",
    "        return (self.value(x+0.001)-self.value(x))/0.001\n",
    "    \n",
    "def optimise(f,x0):\n",
    "    bestVal,bestX = f.value(x0),x0\n",
    "    for i in range(50):\n",
    "        x0 += f.derivative(x0) / (i+1)\n",
    "        if f.value(x0) > bestVal: bestVal,bestX = f.value(x0),x0\n",
    "    return bestVal,bestX\n",
    "```\n",
    "Now any user that wants to create their own function can define\n",
    "```Python\n",
    "class MyFunction(AbstractFunction):\n",
    "    def value(self,x):\n",
    "        return -x*x\n",
    "    def derivative(self,x): \n",
    "        return -2*x\n",
    "optimise(MyFunction(),3.5)\n",
    "```\n",
    "However they could also leave out the second method, and it would simply default to the approximation. Either way your optimiation algorithm can simply assume that the object passed to it will have both a `.value()` and a `.derivative()` method defined, without having to worry about whether the latter is the approximation or a user defined function.\n",
    "\n",
    "The HTML parsing works similarly. To use the `html.parser` library you create a `HTMLParser` subclass which defines your parser. To parse a HTML page you need to \"feed\" the HTML to a parser object. The parser will then go through the text and call a method of your custom parser class for every part of the document it finds such as a start tag or end tag. See the [html.parser documentation](https://docs.python.org/3/library/html.parser.html) for more details.\n",
    "\n",
    "Below is a code template for you to complete. This should use:\n",
    "* The `handle_starttag()` method to detect if you are at the start of a paper. In the HTML these are `<div class=\"...\">` tags where the class value contains the string `\"endering_researchoutput_portal-short`.\n",
    "* The `handle_starttag()` method to detect `<a rel=\"Person\" href=\"...\">` tags that identify authors that are part of Monash staff and their unique URL.\n",
    "* The end of the author list is marked by a `<span class=\"date\">` tag\n",
    "* The start of the author list occurs after a `</h2>` (end) tag\n",
    "* The `handle_endtag()` to detect when the end of a paper (`</div>`)\n",
    "* The `handle_data()` method to deal with author data (strings spearated by \",\" or \"&\"). Note that these are always of the form \"lastname, A.\" with one or more initials. Also there is typically an extra comma at the end of the author list (befe the `<span class=\"date\">`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "import requests\n",
    "\n",
    "class Paper:\n",
    "    def __init__(self):\n",
    "        self.authors=[]\n",
    "        self.internal=[] # URLs of Monash co-authors\n",
    "    \n",
    "class StaffPageParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.papers = []\n",
    "        self.inPaper = self.inAuthors = False\n",
    "    def load(self,authorURL):\n",
    "        self.url = authorURL # identifier for the person\n",
    "        for p in range(100): # pages\n",
    "            html = requests.get(authorURL+\"/publications/?page=%d\"%p).text\n",
    "            numPapers = len(self.papers)\n",
    "            self.feed(html) # call the parser with the HTML from this page\n",
    "            if len(self.papers) == numPapers: break # no more to do here\n",
    "    def get_name(self):\n",
    "        \"Extract name from the URL\"\n",
    "        return (\" \".join(self.url.split(\"/\")[-1].split(\"-\"))).title()\n",
    "    def handle_starttag(self,tag,attrs):\n",
    "        pass # add your implementation here\n",
    "    def handle_endtag(self,tag):\n",
    "        pass # add your implementation here\n",
    "    def handle_data(self,data):\n",
    "        pass # add your implementation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Baatar, D. | Krishnamoorthy, M. | Ernst, A. T.\n",
      "1: Dayama, N. R. | Krishnamoorthy, M. | Ernst, A. T. | Rangaraj, N. | Narayanan, V.\n",
      "1: Kartal, Z. | Ernst, A. T.\n",
      "1: Bunton, J. D. | Ernst, A. T. | Hanson, J. O. | Beyer, H. L. | Hammill, E. | Runge, C. A. | Venter, O. | Possingham, H. P. | Rhodes, J. R.\n",
      "1: Roozbahani, R. | Huston, C. | Dunstall, S. | Abbasi, B. | Ernst, A. | Schreider, S.\n",
      "1: Connor, J. D. | Bryan, B. A. | Nolan, M. | Stock, F. | Gao, L. | Dunstall, S. | Graham, P. | Ernst, A. T. | Newth, D. | Grundy, M. | Hatfield-Dodds, S.\n",
      "1: Singh, G. | Ernst, A. T. | Baxter, M. | Sier, D.\n",
      "1: Stock, F. | Dunstall, S. | Ayre, M. | Ernst, A. | Nazari, A. | Thiruvady, D. | King, S.\n",
      "1: Xie, J. | Mei, Y. | Ernst, A. T. | Li, X. | Song, A.\n",
      "2: Thiruvady, D. R. | Ernst, A. T. | Wallace, M.\n"
     ]
    }
   ],
   "source": [
    "# test code.\n",
    "URL=\"https://research.monash.edu/en/persons/andreas-ernst\"\n",
    "person=StaffPageParser()\n",
    "person.load(URL)\n",
    "for p in person.papers[30:40]:  # check some arbitrary part of the publication list\n",
    "    print(\"%d:\"%len(p.internal),\" | \".join(p.authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets read all of the departmental data\n",
    "The following code should \"just work\" assuming that the above is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPARTMENT=\"school-of-mathematics\"\n",
    "staffurls = findAllStaff(DEPARTMENT)\n",
    "allstaff = []\n",
    "for i,url in enumerate(staffurls):\n",
    "    person = StaffPageParser()\n",
    "    person.load(url)\n",
    "    allstaff.append(person)\n",
    "    if i%6 == 0: # print occasionally to show that it's still working\n",
    "        print(\"%s:\\t%5d authors\"% (url.split(\"/\")[-1],sum(len(p.authors) for p in person.papers)))\n",
    "print(\"Read data from %d staff with %d papers (total)\"% \n",
    "      (len(allstaff),sum(len(s.papers) for s in allstaff)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving interim result\n",
    "The above code probably took some time to run. You may not want to do this again, particularly as we move to the next part which focusses on reporting.\n",
    "Hence it might be useful to save what we have so far to a file. What is the best way to do this?\n",
    "\n",
    "There are a number of alternative options, with different advantages & disadvantages:\n",
    "\n",
    "* `pickle` is a standard library function that can dump almost any Python object into a file and restore it again. This is python specific, fairly compact, quite fast. A good option when just wanting to store objects short term in files for your own use. The only way to do this is relatively simple:\n",
    "```python\n",
    "import pickle\n",
    "with out as open(\"filename\",\"wb\"):\n",
    "    pickle.dump(object,out) # could also dump multiple objects into one file\n",
    "newobj = pickle.load(open(\"filename\",\"r\"))\n",
    "```\n",
    "Note the use of `\"wb\"` as file mode - the file is being written in binary\n",
    "* `json` is a library for writing/reading data in the \"standard\" [JSON format](https://en.wikipedia.org/wiki/JSON) that was originally designed for JavaScript. It is human-readable, supports a variety of languages, only really supports Python built in types, and is somewhat verbose (though not as verbose as XML). Basic usage is the same as for pickle using the `json.dump` and `json.load` functions (except that you can write as plain text). So if you want to dump anything else, you need to convert your custom classes to lists and dictionaries.\n",
    "* Write some custom save/load routines - gives greatest flexibility but requires significantly more effort.\n",
    "\n",
    "Note that in order to save space we could also write a compressed file rather than a normal file. Various [compression libraries](https://docs.python.org/3.8/library/archiving.html) are available for Python, here we are going to test just one of these `gzip` provides a simple file interface for reading/writing compressed files like normal text files: Use `gzip.open()` to create a file to read/write just as with `open()`. Note that gzip files are only able to write binary strings so we need to `.encode()` any string before we are able to write it to file.\n",
    "\n",
    "For the exercise below you need to convert our list of `StaffPageParser` objects into an appropriate list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pickle: 417436\n",
      "      json: 336783\n",
      "   json.gz: 25202\n"
     ]
    }
   ],
   "source": [
    "import gzip,pickle,json\n",
    "#\n",
    "# add a bit of code here to write your file to \n",
    "# `data.pickle`, `data.json`, `data.pickle.gz` and `data.json.gz`\n",
    "# These should contained the pickled/json'ed and perphas gzip'ed version of the data\n",
    "\n",
    "import os.path # to compare size of files produced with each approach\n",
    "for ext in [\"pickle\", \"json\", \"json.gz\"]:\n",
    "    print(\"%10s: %d\" % (ext, os.path.getsize(\"data.\"+ext)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test restoration\n",
    "print(\"allstaff list: %d papers\"%sum(len(s.papers) for s in allstaff))\n",
    "with open(\"data.pickle\",\"rb\") as infile: dat = pickle.load(infile)\n",
    "print(\"allstaff list: %d papers\"%sum(len(s.papers) for s in dat))\n",
    "\n",
    "## you may want to test some of the other formats as well ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a report\n",
    "\n",
    "In one sense this is pretty easy. If you are writing a scientific paper you are likely to be using LaTeX which is all text based, though you could just as easily write a html document. You just need to have some basic idea of the syntax of the document format that you are using. Or, if you are really desparate, you can even use Microsoft Word's docx format using [python-docx](https://python-docx.readthedocs.io/en/latest/).\n",
    "\n",
    "### Useful python methods\n",
    "There are a number of ways of formatting text that can be used in Python, experiment with some of these and choose whichever is the most appropriate for what you are doing.\n",
    "\n",
    "Throughout this the to be used is a creating a fragment of LaTeX that looks like this:\n",
    "```LaTeX\n",
    "\t\\title{A very important paper} \\date{Revision: 2.53} \n",
    "\t\\authors{Mary Jones \\& John Smith}  \n",
    "```\n",
    "I assume that you have local variables `title=\"A very important paper\"`, `ver=2.530` and\n",
    "`author=[\"Mary Jones\", \"John Smith\"]`. Note that we have to be careful about use of `\\` in Python strings (either escape these or use raw strings like `r\"\\\"`)\n",
    "\n",
    "* The `%` operator is best known and works like `printf()` in C (and other languages that have adopted this formatting convention). See [documentation](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)\n",
    "```Python\n",
    "\"\\t\\\\title{%s} \\\\date{Revision: %.2f}\\n\\t\\\\authors{%s}\"%(title,ver,r\" \\& \".join(author)) \n",
    "```\n",
    "* For large strings we might want to identify the fields by name rather than having to remember the exact order in which they appear. The `%` operator can work with a dictionary rather than a tuple, but now all fields to be replaced must be named in brackets:\n",
    "```Python\n",
    "\"\\t\\\\title{%(Title)s} \\\\date{Revision: %(Rev).2f}\\n\\t\\\\authors{%(Auth)s}\"% {\n",
    "    \"Auth\": r\" \\& \".join(author), \"Rev\":ver, \"Title\":title  }\n",
    "```\n",
    "* For large strings we might want to identify the fields by name rather than having to remember the exact order in which they appear. The `.format` method on strings allows you to specify values either by position in the argument list (e.g. `{2}` would be the third argument) or by name (e.g. `{val}` would substitute 3.5 in `.format(val=3.5)`). In addition can specify a range of formatting options by following the name or number with `:` and a format (eg `:5.3f`). The formatting for fields is more flexible than with `%`, see the [format specification mini language](https://docs.python.org/3/library/string.html?highlight=string#format-specification-mini-language) for details. You need to use `{{ }}` to insert `{ }` given the special meaning of the braces. \n",
    "```python\n",
    "r\"\"\"\\title{{{0}}} \\date{{Revision: {Rev:.2f}}}\n",
    "\\authors{{ {Auth:^30} }}\"\"\".format(title,Auth=r\" \\& \".join(author), Rev=ver) )\n",
    "```\n",
    "* The template mechanism looks more like shell script string replacements using a `$` followed by a name to identify values to be replaced. The name may optionally be enclosed in braces. You need to first define a `Template(\"templatestring\")` and then use `.substitute()` to substitute for each of the `$` values. This function takes keyword arguments (like `.format()`) or a dictionary to obtain the values. This is pretty easy to use, particulary with `locals()` to create a dictionary of local variables. However, it has far fewer formatting options that the other methods\n",
    "\n",
    "Here are the different options in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using %:\n",
      "\t\\title{A very important paper} \\date{Revision: 2.53}\n",
      "\t\\authors{Mary Jones \\& John Smith}\n",
      "Using % with dictionary:\n",
      "\t\\title{A very important paper} \\date{Revision: 2.53}\n",
      "\t\\authors{Mary Jones \\& John Smith}\n",
      "Using format:\n",
      "\t\\title{A very important paper} \\date{Revision: 2.53}\n",
      "\t\\authors{    Mary Jones \\& John Smith    }\n",
      "Using Template:\n",
      "\t\\title{A very important paper} \\date{Revision: 2.531}\n",
      "\t\\authors{Mary Jones \\& John Smith}\n"
     ]
    }
   ],
   "source": [
    "from string import Template\n",
    "author = [\"Mary Jones\", \"John Smith\"]\n",
    "ver=2.531\n",
    "title = \"A very important paper\"\n",
    "print(\"Using %:\\n\"+\n",
    "    \"\\t\\\\title{%s} \\\\date{Revision: %.2f}\\n\\t\\\\authors{%s}\"%(title,ver,r\" \\& \".join(author)) )\n",
    "print(\"Using % with dictionary:\\n\"+\n",
    "\"\\t\\\\title{%(Title)s} \\\\date{Revision: %(Rev).2f}\\n\\t\\\\authors{%(Auth)s}\"% {\n",
    "    \"Auth\": r\" \\& \".join(author), \"Rev\":ver, \"Title\":title  })\n",
    "print(\"Using format:\\n\"+\n",
    "    r\"\"\"\t\\title{{{0}}} \\date{{Revision: {Rev:.2f}}}\n",
    "\t\\authors{{ {Auth:^30} }}\"\"\".format(title,Auth=r\" \\& \".join(author), Rev=ver) )\n",
    "template = Template(r\"\"\"\t\\title{$title} \\date{Revision: ${ver}}\n",
    "\t\\authors{$auth}\"\"\")\n",
    "print(\"Using Template:\\n\"+ template.substitute(locals(),auth=\" \\\\& \".join(author)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Exercise\n",
    "Create a brief pdf report from the data that you have gathered. \n",
    "This report should contain a brief table of the members of the department and the number of unique coauthors that each has inside & outside of Monash. In addition include at least one graph showing something about the data.\n",
    "\n",
    "Below is a class that provides some of the basics, you just need to fill in the gaps.\n",
    "\n",
    "Extra Python hints:\n",
    "* `print()` takes an extra optional argument `file=f` so that you can print to file `f` rather than to the screen\n",
    "* To convert you LaTeX to a pdf use `os.system(\"pdflatex filename.tex\")` to call latex and create `filename.pdf`. Of course this only works if you have pdflatex installed somewhere on your computer where Python can find it. (Or use [https://maxima.erc.monash.edu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "import os\n",
    "\n",
    "class ReportGenerator:\n",
    "    docHeader=Template(r\"\"\"\\documentclass[11pt,a4paper]{article}\n",
    "    \\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm]{geometry}\n",
    "    \\usepackage{graphicx}\n",
    "    $customformat\n",
    "    \\title{$title} \\author{$author}\n",
    "    \\begin{document} \\maketitle\"\"\")\n",
    "    docFooter=r\"\\end{document}\"\n",
    "    tableHeader=r\"\"\"\\begin{table}[htb] \\centering\n",
    "    \\begin{tabular}{lrr|lrr}\\hline % two sets of columns\n",
    "    Name & External & Internal &  Name & External & Internal\\\\\\hline \"\"\" \n",
    "    colSep=\" & \"\n",
    "    rowSep=r\"\\\\\"+\"\\n\"\n",
    "    tableFooter=r\"\"\"\\end{tabular}\n",
    "    \\caption{Number of unique coauthors for each academic.} \\end{table}\"\"\"\n",
    "    figTemplate=Template(r\"\"\"\\begin{figure}[htb]\\centering\n",
    "    \\includegraphics[width=0.8\\textwidth]{$filename} % a .png file is fine\n",
    "    \\caption{$caption} \n",
    "    \\end{figure}\"\"\")\n",
    "    pdfcommand = \"pdflatex -interaction=nonstopmode %(filename)s\"\n",
    "    def __init__(self,filename):\n",
    "        self.filename = filename\n",
    "        self.out = open(filename,\"w\")\n",
    "        if not self.out: return \"ERROR: cannot open\"+filename\n",
    "    def startDoc(self,title,author,customformat=\"\"):     \n",
    "        pass # add your code here or create a subclass\n",
    "    def addTable(self,data):\n",
    "        pass # add your code here or create a subclass\n",
    "    def addFigure(self,data):\n",
    "        pass # add your code here or create a subclass\n",
    "    def endDoc(self):\n",
    "        print(self.docFooter,file=self.out)\n",
    "        self.out.close() # must close before processing\n",
    "    def makePDF(self):\n",
    "        status = os.system(self.pdfcommand % self.__dict__ )\n",
    "        # second last line of the log file should contain the an erorr message if this fails\n",
    "        print(open(self.filename.replace(\".tex\",\".log\"),\"r\").readlines()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** It should be fairly trivial to change from say LaTeX to HTML format reporting, just by changing the class constants, without having to modify any of the rest of the code (depending on how complicated the rest is).\n",
    "\n",
    "Please complete the report generator and submit both the Python/Notebook source and the PDF file generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside on other web based data\n",
    "\n",
    "\n",
    "### Using internal web pages\n",
    "\n",
    "We might want to look up the Monash's internal directory server to find out who is in the school. How to do this? Look at the staff directory available at [https://mids.monash.edu]. If you search, for example, \"School of Mathematics\" it gives you a complete list of all staff (plus some other phone numbers which the name is '--'). This is clearly designed for human use. However, inspecting the underlying javascript shows that what is making this interface work is some simple web services:\n",
    "* [https://mids.monash.edu/mids/items]: provides a complete list of all \"items\" (\"person\" and \"entity\"). We need this to look up the entity id of the department we are interested in\n",
    "* `https://mids.moonash.edu/mids/people?entity=iii` where iii is the entity id of the deparment we are trying to search\n",
    "\n",
    "Both of these URL's return text (in fact JSON formatted data) that is quite easy to parse. So it would be tempting to try to use this directory server directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      <img src=\"https://ok6static.oktacdn.com/fs/bcg/4/gfs1r5zh8mUIyqEXF2p7\" alt=\"MIDS\" class=\"logo monashuniversity_mids_1\"/></div>\n",
      "              <p>Sign-in with your Monash University account to access MIDS</p>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen  # just to remind you where this function comes from\n",
    "\n",
    "data = urlopen(\"https://mids.monash.edu/mids/items/\"\n",
    "              ).read().decode(\"utf-8\")  # read & convert to a unicode python string\n",
    "# print(data) # too verbose\n",
    "print( \"\\n\".join( line for line in data.split(\"\\n\") if \"MIDS\" in line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happened here?** If you open [https://mids.monash.edu/mids/items/] in your browser (and if you have not yet opened any Monash intranet sites) you will first get an okta login screen. After that the browser will show you the data you actually want:\n",
    "```[{\"person_id\":28479,\"name\":...```\n",
    "For the purpose of just testing the use of JSON, you could try opening [https://mids.monash.edu/mids/people/?entity=216] (the maths school directory) in a web browser and doing a `Save As...` in your file browser to create a file `maths-directory.json`. With this file you should then be able to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [{\"surname\": \"Mayer\", \"full_phone_number\": \"+61 3 990 54465\", \"entity\": {\"id\": 216, \"nam\n"
     ]
    }
   ],
   "source": [
    "# result of https://mids.monash.edu/mids/people/?entity=216  (after providing password)\n",
    "data = open(\"maths-directory.json\",\"r\").read() \n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add code to \n",
    " 1. convert the JSON to python data, \n",
    " 2. only get the \"results\" part, \n",
    " 3. filter out non-people (where surname='-')\n",
    " 4. print the result (perhaps by converting to a `pandas.DataFrame`)\n",
    " \n",
    " Useful functions for dealin with JSON data:\n",
    " * `eval(\"some python code\")` : JSON looks a lot like a combination of lists and dictonaries. So you could convert the text you read by simply calling eval on the result. However while that might work, it's preferable to use the dedicated JSON library to do this\n",
    "* `import json` loads the library dedicated to dealing with this kind of data, and `json.loads('[\"some text\"]')` will load from a string. Or use `json.load(input)` to load directly from input (any \"file-like\" object, such as the url request)\n",
    "* The `pandas` library has a `pandas.DataFrame` constructor that automatically take a list of dictionaries (where all dictionaries have the same keys) and convert them to a table. You could also experiment with `pandas.read_json()` - see [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
